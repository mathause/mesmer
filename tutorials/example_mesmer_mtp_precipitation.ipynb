{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains an example of MESMER-M-TP. The steps for working with MESMER-M-TP are the following\n",
    "i. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import mesmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_precipitation(pr_in_kgms, n_digits=10):\n",
    "    \"\"\"\n",
    "    precipitation data from ESMs does usually not contain a cut-off value\n",
    "    therefore, the models usually do not output zero-percipitation, but rather\n",
    "    very small residual values and sometimes also very small negative values.\n",
    "    This function converts precipitation from kg/m^2/s to mm/day andapplies\n",
    "    a cut-off to set very small precipitation values to zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pr_in_kgms: ndarray\n",
    "        Precipitation data in kg/m^2/s\n",
    "    n_digits: int\n",
    "        number of digits behind the . to keep, precipitaiton is rounded and small\n",
    "        values are rounded to 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pr_in_mm : ndarray with same shape as pr_in_kgms\n",
    "        Precipitation data in mm/day rounded s.t. only n digits after . are kept\n",
    "    \"\"\"\n",
    "\n",
    "    pr_in_mm = pr_in_kgms * 86400\n",
    "    # size                                    = len(pr_in_mm[pr_in_mm < 1*10**(-10)])\n",
    "    pr_in_mm[pr_in_mm < 1 * 10 ** (-10)] = 1 * 10 ** (-n_digits)\n",
    "    pr_in_mm = np.round(pr_in_mm, n_digits)\n",
    "    return pr_in_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functionalities\n",
    "def load_training_data(\n",
    "    tas_hist_mon,\n",
    "    tas_proj_mon,\n",
    "    pr_hist_mon,\n",
    "    pr_proj_mon,\n",
    "    REFERENCE_PERIOD,\n",
    "    THRESHOLD_LAND,\n",
    "):\n",
    "\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "    tas_mon = xr.open_mfdataset(\n",
    "        [tas_hist_mon, tas_proj_mon],\n",
    "        combine=\"by_coords\",\n",
    "        combine_attrs=\"override\",\n",
    "        data_vars=\"minimal\",\n",
    "        compat=\"override\",\n",
    "        coords=\"minimal\",\n",
    "        drop_variables=[\"height\", \"file_qf\"],\n",
    "        decode_times=time_coder,\n",
    "    ).load()\n",
    "\n",
    "    # data preprocessing\n",
    "    # create global mean tas anomlies timeseries\n",
    "    tas_mon = mesmer.grid.wrap_to_180(tas_mon)\n",
    "    # convert the 0..360 grid to a -180..180 grid to be consistent with legacy code\n",
    "\n",
    "    ref = (\n",
    "        tas_mon.groupby(\"time.year\")\n",
    "        .mean()\n",
    "        .sel(year=REFERENCE_PERIOD)\n",
    "        .mean(\"year\", keep_attrs=True)\n",
    "    )\n",
    "    tas_mon = tas_mon - ref\n",
    "\n",
    "    # create local gridded tas data\n",
    "    def mask_and_stack(ds, threshold_land):\n",
    "        ds = mesmer.mask.mask_ocean_fraction(ds, threshold_land)\n",
    "        ds = mesmer.mask.mask_antarctica(ds)\n",
    "        ds = mesmer.grid.stack_lat_lon(ds)\n",
    "        return ds\n",
    "\n",
    "    tas_stacked_mon = mask_and_stack(tas_mon, threshold_land=THRESHOLD_LAND)\n",
    "\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "    pr_mon = xr.open_mfdataset(\n",
    "        [pr_hist_mon, pr_proj_mon],\n",
    "        combine=\"by_coords\",\n",
    "        combine_attrs=\"override\",\n",
    "        data_vars=\"minimal\",\n",
    "        compat=\"override\",\n",
    "        coords=\"minimal\",\n",
    "        drop_variables=[\"height\", \"file_qf\"],\n",
    "        decode_times=time_coder,\n",
    "    ).load()\n",
    "\n",
    "    # data preprocessing\n",
    "    # create global mean tas anomlies timeseries\n",
    "    pr_mon = mesmer.grid.wrap_to_180(pr_mon)\n",
    "    pr_stacked_mon = mask_and_stack(pr_mon, threshold_land=THRESHOLD_LAND)\n",
    "\n",
    "    pr_stacked_mon[\"pr\"].data = converting_precipitation(pr_stacked_mon[\"pr\"].data)\n",
    "\n",
    "    return (tas_stacked_mon, pr_stacked_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure where this function belong thematically\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "\n",
    "def get_closest_locations(gridcells, n_closest=150):\n",
    "    \"\"\"\n",
    "    Given an array of (lat, lon) coordinates, this function computes the pairwise distance\n",
    "    between all coordinate locations in the array and then returns an array\n",
    "    of indices that gives the indices of the n_closest locations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_path: str or Path\n",
    "        String or pahtlib.Path object pointing to an .npy file that contains an array of shape (n_locations, 2)\n",
    "        tghat contains (lat, lon) coordinates for all n_locations\n",
    "    n_closest: int\n",
    "        number of closest locations to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_loc_: list of ndarrays\n",
    "        Contains the indices of the n_closest coordinates for each location. That is, for the location\n",
    "        with index i, i.e. coords[i], the coordinates of the n_closest locations are\n",
    "        given by coords[selected_loc_[i]]\n",
    "\n",
    "    \"\"\"\n",
    "    lats = gridcells[\"lat\"].values\n",
    "    lons = gridcells[\"lon\"].values\n",
    "    n_gridcells = len(lats)\n",
    "    coords = np.array([[lats[i], lons[i]] for i in range(n_gridcells)])\n",
    "    dist = (\n",
    "        haversine_distances(np.pi / 180 * coords, np.pi / 180 * coords) * 6371\n",
    "    )  # *6371000/1000  to conver to km\n",
    "    selected_loc_ = [np.argsort(dist[j, :])[:n_closest] for j in range(n_gridcells)]\n",
    "    locations = xr.DataArray(\n",
    "        selected_loc_,\n",
    "        dims=[\"gridcell\", \"closest_gridcells\"],\n",
    "        coords={\n",
    "            \"gridcell\": gridcells.values,\n",
    "            \"closest_gridcells\": np.arange(n_closest),\n",
    "        },\n",
    "    )\n",
    "    # selected_loc      = [np.argwhere(dist[j,:] <= 3500).flatten() for j in range(n_index)] # for computing based on a radius; produces uneven results bc of missing values over ocean\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config values\n",
    "THRESHOLD_LAND = 1 / 3\n",
    "\n",
    "REFERENCE_PERIOD = slice(\"1850\", \"1900\")\n",
    "\n",
    "HIST_PERIOD = slice(\"1850\", \"2014\")\n",
    "PROJ_PERIOD = slice(\"2015\", \"2100\")\n",
    "\n",
    "LOCALISATION_RADII = range(1750, 2001, 250)\n",
    "\n",
    "n_closest = 10\n",
    "n_cov = 1 + 2 * n_closest\n",
    "\n",
    "esm = \"IPSL-CM6A-LR\"\n",
    "scenario = \"ssp585\"\n",
    "run_id_training = \"r1i1p1f1\"\n",
    "test_cmip_generation = 6\n",
    "\n",
    "# define paths and load data\n",
    "CODE_PATH = pathlib.Path(\"/home/scsarah/mesmer\")\n",
    "TEST_DATA_PATH = CODE_PATH / \"tests\" / \"test-data\"\n",
    "TEST_PATH = TEST_DATA_PATH / \"output\" / \"tas\" / \"one_scen_one_ens\"\n",
    "\n",
    "cmip_data_path = mesmer.example_data.cmip6_ng_path(relative=True)\n",
    "\n",
    "path_tas_mon = cmip_data_path / \"tas\" / \"mon\" / \"g025\"\n",
    "tas_hist_mon = path_tas_mon / f\"tas_mon_{esm}_historical_{run_id_training}_g025.nc\"\n",
    "tas_proj_mon = path_tas_mon / f\"tas_mon_{esm}_{scenario}_{run_id_training}_g025.nc\"\n",
    "\n",
    "path_pr_mon = cmip_data_path / \"pr\" / \"mon\" / \"g025\"\n",
    "pr_hist_mon = path_pr_mon / f\"pr_mon_{esm}_historical_{run_id_training}_g025.nc\"\n",
    "pr_proj_mon = path_pr_mon / f\"pr_mon_{esm}_{scenario}_{run_id_training}_g025.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_stacked_mon, pr_stacked_mon = load_training_data(\n",
    "    tas_hist_mon,\n",
    "    tas_proj_mon,\n",
    "    pr_hist_mon,\n",
    "    pr_proj_mon,\n",
    "    REFERENCE_PERIOD,\n",
    "    THRESHOLD_LAND,\n",
    ")\n",
    "# generate a temperature array where 'month'\n",
    "# is an explicit dimension\n",
    "time = tas_stacked_mon.time\n",
    "tas_stacked_mon_grouped = tas_stacked_mon.copy()\n",
    "tas_stacked_mon_grouped = tas_stacked_mon_grouped.assign_coords(\n",
    "    year=time.dt.year, month=time.dt.month\n",
    ")\n",
    "tas_stacked_mon_grouped = tas_stacked_mon_grouped.groupby([\"year\", \"month\"]).mean(\n",
    "    dim=\"time\"\n",
    ")\n",
    "\n",
    "time = pr_stacked_mon.time\n",
    "pr_stacked_mon_grouped = pr_stacked_mon.copy()\n",
    "pr_stacked_mon_grouped = pr_stacked_mon_grouped.assign_coords(\n",
    "    year=time.dt.year, month=time.dt.month\n",
    ")\n",
    "pr_stacked_mon_grouped = pr_stacked_mon_grouped.groupby([\"year\", \"month\"]).mean(\n",
    "    dim=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_locations = get_closest_locations(\n",
    "    tas_stacked_mon[\"gridcell\"], n_closest=n_closest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mesmer.stats import SklearnXarrayTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STDSCALER_tas = SklearnXarrayTransformer(\n",
    "    StandardScaler(), sample_dim=\"year\", feature_dim=\"gridcell\", group_dims=[\"month\"]\n",
    ")\n",
    "tas_scaled = STDSCALER_tas.fit_transform(tas_stacked_mon_grouped[\"tas\"])\n",
    "tas_scaling_means_ = STDSCALER_tas.get_params_as_xarray(\"mean_\")\n",
    "tas_scaling_scales_ = STDSCALER_tas.get_params_as_xarray(\"scale_\")\n",
    "\n",
    "STDSCALER_tas_sq = SklearnXarrayTransformer(\n",
    "    StandardScaler(), sample_dim=\"year\", feature_dim=\"gridcell\", group_dims=[\"month\"]\n",
    ")\n",
    "tas_sq_scaled = STDSCALER_tas_sq.fit_transform(tas_stacked_mon_grouped[\"tas\"] ** 2)\n",
    "tas_sq_scaling_means_ = STDSCALER_tas_sq.get_params_as_xarray(\"mean_\")\n",
    "tas_sq_scaling_scales_ = STDSCALER_tas_sq.get_params_as_xarray(\"scale_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesmer.stats import GammaGLMXarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [\n",
    "    21 * [0],\n",
    "    1 * [0] + 20 * [0.1],\n",
    "    1 * [0] + 1 * [0.1] + 9 * [0.2] + 1 * [0.1] + 9 * [0.2],\n",
    "    1 * [0] + 20 * [0.2],\n",
    "    1 * [0] + 1 * [0.2] + 9 * [0.5] + 1 * [0.2] + 9 * [0.5],\n",
    "    1 * [0] + 20 * [0.5],\n",
    "    1 * [0] + 20 * [1],\n",
    "    1 * [0] + 1 * [1] + 19 * [2],\n",
    "    1 * [0] + 20 * [2],\n",
    "    1 * [0] + 20 * [10],\n",
    "    1 * [0] + 20 * [100],\n",
    "    1 * [0] + 20 * [100000],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GammaGLMXarray(alphas, n_jobs=-1)\n",
    "\n",
    "model.fit(\n",
    "    tas=tas_scaled,\n",
    "    tas_sq=tas_sq_scaled,\n",
    "    pr=pr_stacked_mon_grouped[\"pr\"],\n",
    "    closest_locations=closest_locations,\n",
    ")\n",
    "\n",
    "betas = model.params_\n",
    "\n",
    "mu_xr = model.predict(\n",
    "    tas=tas_scaled,\n",
    "    tas_sq=tas_sq_scaled,\n",
    "    closest_locations=closest_locations,\n",
    ")\n",
    "\n",
    "res_xr = model.residuals(pr_stacked_mon_grouped[\"pr\"], mu_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mesmer.stats import XarrayPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_xr_flat = (\n",
    "    res_xr.stack(time=(\"year\", \"month\"))\n",
    "    .drop_vars([\"year\", \"month\"])\n",
    "    .assign_coords(time=time)\n",
    ")\n",
    "\n",
    "# Suppose residuals_da has dims (time, gridcell)\n",
    "steps = [(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=0.98))]\n",
    "\n",
    "xpipe = XarrayPipeline(steps, sample_dim=\"time\", feature_dim=\"gridcell\")\n",
    "\n",
    "# Fit + transform\n",
    "residuals_scaled = xpipe.fit_transform(res_xr_flat)\n",
    "\n",
    "# Access PCA components as xarray\n",
    "components_flat = xpipe.get_params_as_xarray(\"pca\", \"components_\")\n",
    "\n",
    "# components_da will have dims: (\"component\", \"gridcell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_scaled_mon_grouped = residuals_scaled.copy()\n",
    "residuals_scaled_mon_grouped = residuals_scaled_mon_grouped.assign_coords(\n",
    "    year=time.dt.year, month=time.dt.month\n",
    ")\n",
    "residuals_scaled_mon_grouped = residuals_scaled_mon_grouped.groupby(\n",
    "    [\"year\", \"month\"]\n",
    ").mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from mesmer.stats import GroupedKDEXarray\n",
    "\n",
    "kde = KernelDensity(bandwidth=0.05, kernel=\"gaussian\", metric=\"chebyshev\")\n",
    "\n",
    "xkde = GroupedKDEXarray(\n",
    "    kde=kde,\n",
    "    sample_dim=\"year\",\n",
    "    feature_dim=\"component\",\n",
    "    group_dim=\"month\",\n",
    ")\n",
    "\n",
    "xkde.fit(residuals_scaled_mon_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRAWING EMULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variability\n",
    "NR_EMUS = 10\n",
    "SEED = 4294967290\n",
    "m_time = tas_stacked_mon.time\n",
    "N_TS = len(m_time)\n",
    "N_YRS = len(pr_stacked_mon_grouped[\"year\"])\n",
    "N_GRID = len(pr_stacked_mon[\"gridcell\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_var_emus_transformed = xkde.sample(\n",
    "    n_samples=N_YRS * NR_EMUS,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_var_flat = pr_var_emus_transformed.stack(time=(\"month\", \"sample\")).drop_vars(\n",
    "    [\"month\", \"sample\"]\n",
    ")\n",
    "inv_flat = xpipe.inverse_transform(pr_var_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_var_emus = xr.DataArray(\n",
    "    data=inv_flat.data.reshape(NR_EMUS, N_TS, N_GRID),\n",
    "    dims=(\"realisation\", \"time\", \"gridcell\"),\n",
    "    coords={\n",
    "        \"realisation\": np.arange(NR_EMUS),\n",
    "        \"time\": time,\n",
    "        \"gridcell\": tas_stacked_mon[\"gridcell\"].values,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_grid = 50\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pr_var_emus.sel(gridcell=i_grid).values.T, color=\"grey\", alpha=0.5)\n",
    "plt.plot(res_xr_flat.sel(gridcell=i_grid).values, color=\"C0\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
